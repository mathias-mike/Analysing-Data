{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting: wragle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I started off my wrangling process by downloading the `twitter_archive_enhanced.csv` from the udacity classroom and then I read in the file into a `pandas.DataFrame` I called `df_archive`.\n",
    "\n",
    "* Next I used the `requests` library to request for the file stored in the udacity server as [image-predictions.tsv](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv). I initialized a cursor on the `response.text` at position zero with `io.StringIO()` and read this into a `pandas.DataFrame` I called `df_ipred`.\n",
    "\n",
    "* And lastly I queried the twitter API using the `tweepy` twitter access library to fectch `retweet_counts` and `favorite_counts`. First of I needed to create a developer account on twitter and get it approved (*fortunately this was a success for me*) and then I got **keys** and **tokens** that grants me access to the API. I stored the data I got from twitter in a file called `tweet_json.txt` from where I read in the tweet `retweet_counts` and `favorite_counts` into a `pandas.DataFrame` called `df_rt_fav`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I accessed the 3 `pandas.DataFrame`s for quality and tidiness issues and I found the following.\n",
    "\n",
    "#### Quality issues\n",
    "1. Drop retweets and replys\n",
    "\n",
    "2. `NaN` values in columns `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id` and `retweeted_status_timestamp` in `df_archive`.\n",
    "\n",
    "3. Missing values in `expanded_urls` in `df_archive`.\n",
    "\n",
    "4. `timestamp` is of dtype `string` instead of `date_time` in `df_archive`\n",
    "\n",
    "5. `source` should be `categorical` instead of `string` dtype in `df_archive`.\n",
    "\n",
    "6. Rate is 13/10 not 960/00 for tweet with id `835246439529840640` in `df_archive`.\n",
    "\n",
    "7. Date used as rate for tweet with id `832088576586297345` in `df_archive`.\n",
    "\n",
    "8. 24/7 not a rate for tweet with id `810984652412424192` in `df_archive`.\n",
    "\n",
    "9. Rate should be 9.75/10 not 75/10 for tweet with ids `[832215909146226688, 786709082849828864]` and 11.27/10 not 27/10 for tweet with id `778027034220126208`, 11.26/10 not 26/10 for tweet with id `680494726643068929` in `df_archive`.\n",
    "\n",
    "10. Multiple rating for tweet with id `775096608509886464`, 9/11 and 14/10 in `df_archive`.\n",
    "\n",
    "11. Tweet `740373189193256964` and `775096608509886464` are the same. `775096608509886464` is a retweet of `740373189193256964` in `df_archive`.\n",
    "\n",
    "12. Multiple rating for tweet with id `722974582966214656` in `df_archive`.\n",
    "\n",
    "13. 50/50 and 7/11 not a rate, rate should be 11/10 and 10/10 respectively for tweets with ids `716439118184652801` and `682962037429899265` in `df_archive`.\n",
    "\n",
    "14. `None` in columns `name`, `doggo`, `floofer`, `pupper` and `puppo` in `df_archive`.\n",
    "\n",
    "15. `None` in columns instead of `NaN` for missing values [`name`, `dog_stage`].\n",
    "\n",
    "\n",
    "#### Tidiness issues\n",
    "1. `doggo`, `floofer`, `pupper` and `puppo` should be under one variable name `dog_stage`.\n",
    "\n",
    "2. `df_ipred` should be modified to `prediction_no`, `prediction`, `confidence` and `is_dog`.\n",
    "\n",
    "3. Merge `df_rt_fav` with `df_archive`.\n",
    "\n",
    "4. Multiple values in `expanded_url`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I made sure to clean all above stated quality and tidiness issue via the method well documented in the `wrangle_act.ipynb` file and then stored my cleaned `pandas.DataFrame`s as `.csv` and into an `SQL` database."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
