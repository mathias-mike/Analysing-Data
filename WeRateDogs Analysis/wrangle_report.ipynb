{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting: wragle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I started off my wrangling process by downloading the `twitter_archive_enhanced.csv` from the udacity classroom and then I read in the file into a `pandas.DataFrame` I called `df_archive`.\n",
    "\n",
    "* Next I used the `requests` library to request for the file stored in the udacity server as [image-predictions.tsv](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv). I initialized a cursor on the `response.text` at position zero with `io.StringIO()` and read this into a `pandas.DataFrame` I called `df_ipred`.\n",
    "\n",
    "* And lastly I queried the twitter API using the `tweepy` twitter access library to fectch `retweet_counts` and `favorite_counts`. First of I needed to create a developer account on twitter and get it approved (*fortunately this was a success for me*) and then I got **keys** and **tokens** that grants me access to the API. I stored the data I got from twitter in a file called `tweet_json.txt` from where I read in the tweet `retweet_counts` and `favorite_counts` into a `pandas.DataFrame` called `df_rt_fav`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I accessed the 3 `pandas.DataFrame`s for quality and tidiness issues and I found the following.\n",
    "\n",
    "#### Quality issues\n",
    "1. Drop retweets and replys.\n",
    "\n",
    "2. Missing values in `expanded_urls` in `df_archive`.\n",
    "\n",
    "3. tweet_id should be `string` not `int` accross all 3 datasets.\n",
    "\n",
    "4. `timestamp` is of dtype `string` instead of `date_time` in `df_archive`\n",
    "\n",
    "5. `source` should be `categorical` instead of `string` dtype in `df_archive`.\n",
    "\n",
    "6. Incorrect rates in `df_archive`, e.g, 75/10 instead of 9.75/10...\n",
    "\n",
    "7. Incorrect dog names, `a`, `such`, `quite` `None`...\n",
    "\n",
    "8. `None` in columns `name`, `doggo`, `floofer`, `pupper` and `puppo` in `df_archive`.\n",
    "\n",
    "\n",
    "#### Tidiness issues\n",
    "1. `doggo`, `floofer`, `pupper` and `puppo` should be under one variable name `dog_stage`.\n",
    "\n",
    "2. Merge `df_rt_fav` with `df_archive`.\n",
    "\n",
    "3. `df_ipred` should be modified to `prediction_no`, `prediction`, `confidence` and `is_dog`.\n",
    "\n",
    "4. Multiple values in `expanded_url`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I made sure to clean all above stated quality and tidiness issue via the method well documented in the `wrangle_act.ipynb` file and then stored my cleaned `pandas.DataFrame`s as `.csv` and into an `SQL` database."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
