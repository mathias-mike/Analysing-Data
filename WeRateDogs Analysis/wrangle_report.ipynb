{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting: wragle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I started off my wrangling process by downloading the `twitter_archive_enhanced.csv` from the udacity classroom and then I read in the file into a `pandas.DataFrame` I called `df_archive`.\n",
    "\n",
    "* Next I used the `requests` library to request for the file stored in the udacity server as [image-predictions.tsv](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv). I initialized a cursor on the `response.text` at position zero with `io.StringIO()` and read this into a `pandas.DataFrame` I called `df_ipred`.\n",
    "\n",
    "* And lastly I queried the twitter API using the `tweepy` twitter access library to fectch `retweet_counts` and `favorite_counts`. First of I needed to create a developer account on twitter and get it approved (*fortunately this was a success for me*) and then I got **keys** and **tokens** that grants me access to the API. I stored the data I got from twitter in a file called `tweet_json.txt` from where I read in the tweet `retweet_counts` and `favorite_counts` into a `pandas.DataFrame` called `df_rt_fav`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I accessed the 3 `pandas.DataFrame`s for quality and tidiness issues and I found the following.\n",
    "\n",
    "#### Quality issues\n",
    "##### `df_archive`\n",
    "1. Missing values (`in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id`, `retweeted_status_timestamp`, `expanded_urls`).\n",
    "\n",
    "2. Multiple values in `expanded_url`.\n",
    "\n",
    "3. HTML tags in `source`\n",
    "\n",
    "4. Erroneous datatypes (`tweet_id`, `timestamp`, `source`)\n",
    "\n",
    "5. Incorrect rates (e.g, 75/10 instead of 9.75/10...)\n",
    "\n",
    "6. Incorrect dog names (`a`, `such`, `quite` `None`...)\n",
    "\n",
    "7. `None` in columns `name`, `doggo`, `floofer`, `pupper` and `puppo`.\n",
    "\n",
    "##### `df_rt_fav`\n",
    "8. Erroneous datatypes (`tweet_id`)\n",
    "\n",
    "##### `df_ipred`\n",
    "9. Erroneous datatypes (`tweet_id`)\n",
    "\n",
    "10. Non descriptive column names (`p1, p1_conf, p1_dog, p2, p2_conf, p2_dog, p3, p3_conf, p3_dog`)\n",
    "\n",
    "#### Tidiness issues\n",
    "1. `doggo`, `floofer`, `pupper` and `puppo` should be under one variable name `dog_stage`.\n",
    "\n",
    "2. Merge `df_rt_fav` with `df_archive`.\n",
    "\n",
    "3. Same variables split to different columns `(p1, p2, p3), (p1_conf, p2_conf, p3_conf), (p1_dog, p2_dog, p3_dog)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I made sure to clean all above stated quality and tidiness issue via the method well documented in the `wrangle_act.ipynb` file and then stored my cleaned `pandas.DataFrame`s as `.csv` and into an `SQL` database."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
